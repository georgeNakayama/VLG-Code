# Transformer
_target_: models.decoders.edge_transformer.EdgeTransformer
d_model: 256
nhead: 8 
num_layers: 6
dim_feedforward: 256
dropout: 0.1
activation: relu 
normalize_before: False
return_intermediate: True