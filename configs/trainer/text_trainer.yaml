defaults:
  - optimizer: adamw
  - scheduler: warm_cosine
  - _self_

_target_: trainers.text_trainer.TextTrainer
_recursive_: false

total_batch_size: 524288
max_steps: 19073
max_norm: 1.0
steps_per_eval: 250 
steps_per_save: 5000
lr: 6e-4
scheduler:
  multiplier: 2
  eta_min: 6e-5
  warmup_epoch: 715
optimizer: 
  weight_decay: 0.1
  eps: 1e-8
  betas: [0.9, 0.95]

