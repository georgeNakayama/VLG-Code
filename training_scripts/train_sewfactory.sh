CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 PYTHONPATH=/home/georgenakayama/garment_foundation_model/sewformer/SewFormer:/home/georgenakayama/garment_foundation_model/sewformer/SewFactory/packages torchrun --standalone --nnodes=1 --nproc_per_node=8 training_scripts/train_ds.py experiment.run_name=sewfactory.llava-7b-full-finetune trainer.steps_per_epoch=750 trainer.epoches=20  model.num_freq=0  data_wrapper/dataset=qva_garment_token_dataset  data_wrapper/dataset/garment_tokenizer/standardize=sewfactory_regression_stats model_max_length=500 lora_args.lora_r=0 trainer._target_=trainers.sewfactory_trainer.FinetuneLlavaSewFactoryTrainer data_wrapper/dataset/garment_tokenizer=sewfactory_regression_garment_tokenizer data_wrapper.data_split.load_from_split_file=/home/georgenakayama/garment_foundation_model/sewformer/SewFormer/assets/data_configs/sewfactory_datasplit.json trainer.lr=6e-5 trainer.batch_size=8 trainer.grad_accumulation_steps=5  --config-name train_garment_llava_regression_w_pos --config-path ../configs